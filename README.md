# Teacher-free Feature Distillation
***News! I'm going to have a major update of this repo. The new version will contain most of the methods in Todo list. Please stay tuned.***

This project provides Pytorch implementation for [Self-Regulated Feature Learning via Teacher-free Feature Distillation](https://lilujunai.github.io/Teacher-free-Distillation/).


## Requirements
- python 3.7
- pytorch 1.3.1
- torchvision 0.4.2

## Acknowledgements
This repo is partly based on the following repos, thank the authors a lot.
- [HobbitLong/RepDistiller](https://github.com/HobbitLong/RepDistiller)
- [Knowledge-Distillation-Zoo](https://github.com/AberHu/Knowledge-Distillation-Zoo)

## Citation
If you find that this project helps your research, please consider citing some of the following papers:

```
@inproceedings{li2022TfFD,
    title={Self-Regulated Feature Learning via Teacher-free Feature Distillation},
    author={Li, Lujun},
    booktitle={European Conference on Computer Vision (ECCV)},
    year={2022}
}
```

